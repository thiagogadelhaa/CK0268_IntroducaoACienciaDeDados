{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13498e9f",
   "metadata": {},
   "source": [
    "Neste notebook importarei os dados do site basketball reference(https://www.basketball-reference.com/) para criar um dataset a partir de dados da  temporada regular da NBA desde a temporada 1984-1985(Quando Michael Jordan entrou como novato) até o fim da temporada 2020-2021\n",
    "para analisar como seria a tabela de classificação da temporadas regulares de 2010-2011(Lebron entra no miami heat) até o fim da temporada 2017-2018(Lebron entra no Lakers),caso Michael Jordan entrasse na NBA na temporada 2010-2011\n",
    "\n",
    "(Lembrar de mudar isso )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd0ce58b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.error import URLError, HTTPError\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/537.36'}\n",
    "\n",
    "times = {'Los Angeles Lakers' : 'LAL',\n",
    "        'Milwaukee Bucks' : 'MIL',\n",
    "        'Boston Celtics' : 'BOS',\n",
    "        'Philadelphia 76ers' : 'PHI',\n",
    "        'Portland Trail Blazers' : 'POR',\n",
    "        'Detroit Pistons' : 'DET',\n",
    "        'Denver Nuggets' : 'DEN',\n",
    "        'Dallas Mavericks' : 'DAL',\n",
    "        'Houston Rockets' : 'HOU',\n",
    "        'San Antonio Spurs' : 'SAS',\n",
    "        'New Jersey Nets' : 'NJN',\n",
    "        'Utah Jazz' : 'UTA',\n",
    "        'Golden State Warriors' : 'GSW',\n",
    "        'Chicago Bulls' : 'CHI',\n",
    "        'Cleveland Cavaliers' : 'CLE',\n",
    "        'Indiana Pacers' : 'IND',\n",
    "        'Phoenix Suns': 'PHO',\n",
    "        'Los Angeles Clippers' : 'LAC',\n",
    "        'Atlanta Hawks' : 'ATL',\n",
    "        'Washington Bullets' : 'WSB',\n",
    "        'New York Knicks' : 'NYK',\n",
    "        'Seattle SuperSonics' : 'SEA',\n",
    "        'Toronto Raptors' : 'TOR',\n",
    "        'Miami Heat' : 'MIA',\n",
    "        'Brooklyn Nets' : 'BRK',\n",
    "        'Charlotte Hornets' : 'CHO',\n",
    "        'Washington Wizards' : 'WAS',\n",
    "        'Orlando Magic' : 'ORL',\n",
    "        'Oklahoma City Thunder' : 'OKC',\n",
    "        'Memphis Grizzlies' : 'MEM',\n",
    "        'Sacramento Kings' : 'SAC',\n",
    "        'New Orleans Pelicans' : 'NOP',\n",
    "        'Minnesota Timberwolves' : 'MIN',\n",
    "        'San Diego Clippers' : 'SDC',\n",
    "        'Kansas City Kings' : 'KCK'}\n",
    "\n",
    "anos = ['2020']\n",
    "\n",
    "todos_jogadores = []\n",
    "todos_mvps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702b432",
   "metadata": {},
   "source": [
    "## Funções para pegar os dados de mvps e os dados dos times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbba191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegar_mvps(url, dados_mvps):\n",
    "    \n",
    "    try:\n",
    "        req = Request(url, headers = headers)\n",
    "\n",
    "        response = urlopen(req)\n",
    "        html = response.read()\n",
    "        html = html.decode('utf-8')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    except HTTPError as e:\n",
    "        print(e.status, e.reason)\n",
    "\n",
    "    except URLError as e:\n",
    "        print(e.reason)\n",
    "    \n",
    "    mvps_html = soup.find('tbody').findAll('tr')\n",
    "    \n",
    "    for mvp_html in mvps_html:\n",
    "\n",
    "        dados_mvp = {}\n",
    "        dados_mvp['rank'] = int (mvp_html.find('th').getText())\n",
    "        \n",
    "        nome_jogador = mvp_html.find('td', {'data-stat':'player'}).find('a').getText()\n",
    "        dados_mvp['team'] = mvp_html.find('td', {'data-stat':'team_id'}).getText()\n",
    "        dados_mvp['award_share'] = float(mvp_html.find('td', {'data-stat':'award_share'}).getText())\n",
    "        \n",
    "        dados_mvps[nome_jogador] = dados_mvp\n",
    "\n",
    "\n",
    "def pegar_times_conferencia(soup, dados_times, sufixo):\n",
    "    times_html = soup.find('table', id = f'confs_standings_{sufixo}').find('tbody').findAll('tr')\n",
    "\n",
    "    cont = 1\n",
    "    for time_html in times_html:\n",
    "        dados_time = {}\n",
    "        nome_time = times[time_html.find('th').find('a').getText()]\n",
    "        \n",
    "        \n",
    "        dados_time['conf_rank'] = cont\n",
    "        cont+=1\n",
    "        \n",
    "        time_stats_html = time_html.findAll('td')\n",
    "        \n",
    "        for stat in time_stats_html:\n",
    "            try:\n",
    "                dados_time[stat.get('data-stat')] = float(stat.getText())\n",
    "            except ValueError:\n",
    "                dados_time[stat.get('data-stat')] = 0\n",
    "    \n",
    "        dados_times[nome_time] = dados_time\n",
    "        \n",
    "def pegar_times(url,dados_times):\n",
    "    try:\n",
    "        req = Request(url_dados_time, headers = headers)\n",
    "\n",
    "        response = urlopen(req)\n",
    "        html = response.read()\n",
    "        html = html.decode('utf-8')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    except HTTPError as e:\n",
    "        print(e.status, e.reason)\n",
    "\n",
    "    except URLError as e:\n",
    "        print(e.reason)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"Pegando os dados da Conferência Leste\"\n",
    "    pegar_times_conferencia(soup,dados_times, 'E')\n",
    "    \"Pegando os dados da Conferência Oeste\"\n",
    "    pegar_times_conferencia(soup,dados_times, 'W')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5043af4",
   "metadata": {},
   "source": [
    "## Funções para carregar dados dos jogadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bebeaa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primeiro_scraping_jogadores(url, dados_jogadores, ano):\n",
    "    try:\n",
    "        req = Request(url, headers = headers)\n",
    "\n",
    "        response = urlopen(req)\n",
    "        html = response.read()\n",
    "        html = html.decode('utf-8')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    except HTTPError as e:\n",
    "        print(e.status, e.reason)\n",
    "\n",
    "    except URLError as e:\n",
    "        print(e.reason)\n",
    "    \n",
    "    jogadores_html = soup.find('tbody').findAll('tr')\n",
    "   \n",
    "    i = 0\n",
    "    for jogador_html in jogadores_html:\n",
    "        dados_jogador = {}\n",
    "        if jogador_html.get('class')[0] != 'thead':\n",
    "            \n",
    "            dados_jogador['player'] = jogador_html.find('td', {'data-stat':'player'}).find('a').getText()\n",
    "            dados_jogador['season'] = ano\n",
    "            dados_jogador['pos'] = jogador_html.find('td', {'data-stat':'pos'}).getText()\n",
    "            dados_jogador['age'] = int( jogador_html.find('td', {'data-stat':'age'}).getText() )\n",
    "            \n",
    "            if jogador_html.find('td', {'data-stat':'team_id'}).a == None:\n",
    "                dados_jogador['team'] = jogador_html.find('td', {'data-stat':'team_id'}).getText()\n",
    "            else:\n",
    "                dados_jogador['team'] = jogador_html.find('td', {'data-stat':'team_id'}).a.getText()\n",
    "            \n",
    "            for stat in jogador_html.findAll('td')[4:]:\n",
    "                \n",
    "                try:\n",
    "                    dados_jogador[stat.get('data-stat')] = int(stat.getText())\n",
    "                    \n",
    "                except ValueError:\n",
    "                    if(stat.getText() != ''):\n",
    "                        dados_jogador[stat.get('data-stat')] = float('0' + stat.getText())\n",
    "                    else:\n",
    "                        dados_jogador[stat.get('data-stat')] = 0.0\n",
    "            dados_jogador['mp_pergame'] = round(dados_jogador['mp']/dados_jogador['g'], 1)\n",
    "            dados_jogadores.append(dados_jogador)\n",
    "        else:\n",
    "            i+=1\n",
    "            \n",
    "    print(f'Teste na primeira função:{i}')\n",
    "        \n",
    "def intermedirario_scraping_jogadores(url, dados_jogadores):\n",
    "    try:\n",
    "        req = Request(url, headers = headers)\n",
    "\n",
    "        response = urlopen(req)\n",
    "        html = response.read()\n",
    "        html = html.decode('utf-8')\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    except HTTPError as e:\n",
    "        print(e.status, e.reason)\n",
    "\n",
    "    except URLError as e:\n",
    "        print(e.reason)\n",
    "    \n",
    "    jogadores_html = soup.find('tbody').findAll('tr')\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for jogador_html in jogadores_html:\n",
    "        dados_jogador = dados_jogadores[i]\n",
    "        \n",
    "        if jogador_html.get('class')[0] != 'thead':\n",
    "            i += 1\n",
    "            \n",
    "            stats_jogador = jogador_html.findAll('td')[8:]\n",
    "            for stat in stats_jogador:\n",
    "                try:\n",
    "                    dados_jogador[stat.get('data-stat')] = int(stat.getText())\n",
    "\n",
    "                except ValueError:\n",
    "                    if(stat.getText() == ''):\n",
    "                        dados_jogador[stat.get('data-stat')] = 0.0\n",
    "                    elif stat.getText()[0] == '-':\n",
    "                        dados_jogador[stat.get('data-stat')] =(-1)*float('0' + stat.getText()[1:])\n",
    "                    else:\n",
    "                        dados_jogador[stat.get('data-stat')] = float('0' + stat.getText())\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76435541",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste na primeira função:26\n",
      "{'Giannis Antetokounmpo': {'rank': 1, 'team': 'MIL', 'award_share': 0.952}, 'LeBron James': {'rank': 2, 'team': 'LAL', 'award_share': 0.746}, 'James Harden': {'rank': 3, 'team': 'HOU', 'award_share': 0.363}, 'Luka Dončić': {'rank': 4, 'team': 'DAL', 'award_share': 0.198}, 'Kawhi Leonard': {'rank': 5, 'team': 'LAC', 'award_share': 0.166}, 'Anthony Davis': {'rank': 6, 'team': 'LAL', 'award_share': 0.081}, 'Chris Paul': {'rank': 7, 'team': 'OKC', 'award_share': 0.026}, 'Damian Lillard': {'rank': 8, 'team': 'POR', 'award_share': 0.023}, 'Nikola Jokić': {'rank': 9, 'team': 'DEN', 'award_share': 0.018}, 'Pascal Siakam': {'rank': 10, 'team': 'TOR', 'award_share': 0.017}, 'Jimmy Butler': {'rank': 11, 'team': 'MIA', 'award_share': 0.009}, 'Jayson Tatum': {'rank': 12, 'team': 'BOS', 'award_share': 0.001}}\n"
     ]
    }
   ],
   "source": [
    "for ano in anos:\n",
    "    \"Nesta seção do código serão carregadas as páginas html\"\n",
    "    \n",
    "    url_dados_time = f'https://www.basketball-reference.com/leagues/NBA_{ano}_standings.html'\n",
    "    url_dados_totais_jogador = f'https://www.basketball-reference.com/leagues/NBA_{ano}_totals.html'\n",
    "    url_dados_por_jogo_jogador = f'https://www.basketball-reference.com/leagues/NBA_{ano}_per_game.html'\n",
    "    url_dados_por_36min_jogador = f'https://www.basketball-reference.com/leagues/NBA_{ano}_per_minute.html'\n",
    "    url_dados_por_100pos_jogador = f'https://www.basketball-reference.com/leagues/NBA_{ano}_per_poss.html'\n",
    "    url_dados_avancados_jogador = f'https://www.basketball-reference.com/leagues/NBA_{ano}_advanced.html'\n",
    "    url_votacao_mvp = f'https://www.basketball-reference.com/awards/awards_{ano}.html'\n",
    "    \n",
    "    \n",
    "    \"Aqui será carregado os dados dos candidatos a MVP relativos a este ano\"\n",
    "    \n",
    "    dados_mvps = {}\n",
    "    pegar_mvps(url_votacao_mvp,dados_mvps)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \"Aqui serão carregados os dados do time\"\n",
    "    \n",
    "    \"Aqui é a variável que armazenará os dados do time relativos àquele ano\"\n",
    "    dados_times = {}\n",
    "    \n",
    "    pegar_times(url_dados_time, dados_times)\n",
    "    \n",
    "    \n",
    "    \"Finalmente, serão carregados os dados dos jogadores\"\n",
    "    \n",
    "    dados_jogadores = []\n",
    "    \n",
    "    primeiro_scraping_jogadores(url_dados_totais_jogador, dados_jogadores, int(ano))\n",
    "    \n",
    "    intermedirario_scraping_jogadores(url_dados_por_jogo_jogador, dados_jogadores)\n",
    "    intermedirario_scraping_jogadores(url_dados_por_36min_jogador, dados_jogadores)\n",
    "    intermedirario_scraping_jogadores(url_dados_por_100pos_jogador, dados_jogadores)\n",
    "    intermedirario_scraping_jogadores(url_dados_avancados_jogador, dados_jogadores)\n",
    "    \n",
    "    print(dados_mvps)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7fdfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
